---
layout: post
title:  "Testing the PubMed Search Tester"
date:   2020-05-12
categories: PubMed
---

As I [mentioned earlier]({% post_url 2020-04-21-pubmed-search-tester %}), I've refined the user interface for the [PubMed Search Tester](https://esperr.github.io/pubmed-search-tester/), an application designed to facilitate the process of refining a complex strategy by allowing you to automatically compare different search variants against a *validation set* of "known-good" items.

Of course, the utility of this approach is contingent on whether the relatively small validation sets generated by the Search Tester are large enough to reliably discriminate between different search strategies. I cordially invite you to participate in a research study (UGA IRB ID# PROJECT00001362) to test whether this is the case.

If you agree to take part in this study, you will be directed to a specially modified version of PubMed Search Tester where you’ll find a clinical question as well as a rubric for evaluating which MEDLINE citations might contain the answer to that question. Armed with that rubric, you will evaluate a series of randomly selected citations from a predetermined search strategy and decide whether each citation is a “Good” citation that might answer that question or a “Bad” one that probably would not. Once you complete a question, your choices will be recorded, and you will have the option to continue to another. Each question should take around 10 minutes to complete.
If you agree to participate, please begin by reviewing the formal [Consent Agreement](/assets/Random_Screen_Consent_Letter.pdf). Then start with a very short [demographic questionnaire](https://ugeorgia.ca1.qualtrics.com/jfe/form/SV_a98cyq7oTo6Hkbz) before you continue on to the questions.

Thanks for your help!
